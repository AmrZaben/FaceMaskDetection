{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import splitfolders\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1_measure(y_true, y_pred):\n",
    "    precision_val = precision(y_true, y_pred)\n",
    "    recall_val = recall(y_true, y_pred)\n",
    "    f1 = 2 * (precision_val * recall_val) / (precision_val + recall_val + tf.keras.backend.epsilon())\n",
    "    return f1\n",
    "\n",
    "\n",
    "# Splitting the data into a train(0.8)/test(0.2) split\n",
    "splitfolders.ratio('data', output='train_test', ratio=(0.8, 0.2))\n",
    "\n",
    "# Building CNN layers (3 convolutional layers with max pooling, 1 dense layer, and a softmax output layer)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=(100, 100, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Using generator to input the training and validation images. Also, used image augmentation on the training data.\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ").flow_from_directory('train_test/train',\n",
    "                      color_mode='grayscale',\n",
    "                      target_size=(100, 100),\n",
    "                      batch_size=128,\n",
    "                      class_mode='categorical')\n",
    "\n",
    "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    ").flow_from_directory('train_test/val',\n",
    "                      color_mode='grayscale',\n",
    "                      target_size=(100, 100),\n",
    "                      batch_size=16,\n",
    "                      class_mode='categorical')\n",
    "\n",
    "# Using checkpoints to save models\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model-{epoch:03d}.model', monitor='val_loss', verbose=0,\n",
    "                                                save_best_only=True, mode='auto')\n",
    "\n",
    "# Fitting the model on the data. Saved the model in a variable to compare results\n",
    "history = model.fit(train_generator, epochs=20, validation_data=val_generator, callbacks=[checkpoint])\n",
    "\n",
    "# Loading the best model from training\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the magic function time it to test how fast the model classifies \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.load_model('model-001.model')\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Open an image file\n",
    "img_path = 'data/with_mask/0-with-mask.jpg'\n",
    "img = Image.open(img_path)\n",
    "img = np.array(img)\n",
    "grayscaled = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "face_img = cv2.resize(grayscaled, (100, 100))\n",
    "face_img = face_img / 255.0\n",
    "face_img = np.reshape(face_img, (1, 100, 100, 1))\n",
    "result = model.predict(face_img)\n",
    "\n",
    "\n",
    "labels_dict = {0: 'Wearing a mask', 1: 'Not wearing a mask'}\n",
    "color_dict = {0: (0, 255, 0), 1: (0, 0, 255)}\n",
    "print(result)\n",
    "label = np.argmax(result, axis=1)[0]\n",
    "print(labels_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when you want to use the model in real time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import splitfolders\n",
    "model = tf.keras.models.load_model('model-015.model')\n",
    "\n",
    "# Loading CV2 Haar cascade classifier\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Using webcam\n",
    "source = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "labels_dict = {0: 'Wearing a mask', 1: 'Not wearing a mask'}\n",
    "color_dict = {0: (0, 255, 0), 1: (0, 0, 255)}\n",
    "\n",
    "# Streaming from the webcam\n",
    "while True:\n",
    "    # Reading the image\n",
    "    ret, img = source.read()\n",
    "    # Rescaling the image to gray\n",
    "    grayscaled = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = classifier.detectMultiScale(grayscaled, 1.3, 5)\n",
    "\n",
    "    # Processing the image to fit the CNN\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = grayscaled[y:y + w, x:x + w]\n",
    "        face_img = cv2.resize(face_img, (100, 100))\n",
    "        face_img = face_img / 255.0\n",
    "        face_img = np.reshape(face_img, (1, 100, 100, 1))\n",
    "        result = model.predict(face_img)\n",
    "\n",
    "        label = np.argmax(result, axis=1)[0]\n",
    "\n",
    "        # Size of rectangle border around the face\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color_dict[label], 2)\n",
    "        cv2.rectangle(img, (x, y - 40), (x + w, y), color_dict[label], -1)\n",
    "        cv2.putText(img, labels_dict[label], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('LIVE', img)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    # Break when the esc key is pressed\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
